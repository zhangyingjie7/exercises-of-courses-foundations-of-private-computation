{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixed Precision Encoding\n",
    "\n",
    "Author: \n",
    "- Théo Ryffel - [Twitter](http://twitter.com/theoryffel) - [GitHub](https://github.com/LaRiffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Video] Introduction to FixedPrecision vs FloatPrecision\n",
    "Script:\n",
    "- This section is about fixed precision encoding. Fixed point precision encoding is the counterpart of floating point precision encoding. To better understand what is fixed point precision (or fixed precision in short) and why we use it, let’s start by understanding float precision, the most commonly used encoding.\n",
    "- In statistics, we often deal with real numbers, not integers! This is very helpful for math analysis, especially to be able to use concepts like differentiation that we use intensively during back-propagation when we train a neural network.\n",
    "- But computers are only made of zeros and ones! Therefore we need a way to represent all numbers in terms of 0 and 1, namely we need to find a proper encoding.\n",
    "- So first, we are always considering decimal numbers. If you think of $\\pi$, we can't use it directly, but only a decimal approximation, which might be sufficient for many computations.\n",
    "- The most common way to encode decimal numbers is to encode them on 32 bits, using the float precision encoding. The idea of floating precision is close to the notion of scientific notation : we store separately the most significant numbers (that we call the mantissa), and the exponent, that is a power of 10 (or a power of 2 in practice), and we multiply them together to reconstruct the original number. You can think of the exponent as the position of the point in the decimal notation.\n",
    "- Let's take an example, if I wanted to store 3.14, I would store separately the digits 314 and the position of the point.\n",
    "- It makes it very convenient to store with high fidelity very big and very small numbers: you only need to say that the exponent is very big or very small. This encoding is therefore widely used in practice.\n",
    "- However, when you compute the addition of two floating point numbers with different exponents, you need to convert them to adopt the same exponent, which can be complicated when those numbers are private as in secure multi-computation.\n",
    "- Therefore, we will use fixed precision, that we will explore more in depth just now!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Floating point and fixed point arithmetic\n",
    "\n",
    "In the video above, we've been through the concept of floating point numbers. A schematic way of understanding this encoding is to compare it to the scientific notation.\n",
    "\n",
    "Let's take an example, like $123.456$. The scientific notation is $1.23456 \\times 10^2$, where $1.23456$ is stored on the mantissa and $2$ in the exponent. Depending on the size of the mantissa, we might need to drop the least significant digits and store for example $1.23 \\times 10^2$. In practice, we will use powers of $2$ in the float encoding, but for now we can stick to $10$ for better readability.\n",
    "\n",
    "When we want to add 2 numbers, $123.456$ and $7.3$, which are encoded in such a way that the mantissa only stores the 3 most significant digits, then we can write them $1.23 \\times 10^2$ and $7.3 \\times 10^0$. To be able to add them, we will rewrite the numbers to express them with the same exponent, usually the largest. In our example, we will hence rewrite the addition: $1.23 \\times 10^2 + 0.07 \\times 10^2$. Note that we have lost some precision.\n",
    "\n",
    "You can find more about floating point precision [here](https://www.doc.ic.ac.uk/~eedwards/compsys/float/).\n",
    "\n",
    "Adapting the exponents can be costly when dealing with private numbers, where the mantissa and the exponent are not available in clear text. Therefore, in many implementations of secure multi-party computation, we use fixed point precision encoding, which as you might guess is actually much simpler!\n",
    "\n",
    "Basically, it consists of taking a fixed public exponent for all the numbers involved in the computation. Therefore, we usually consider separately an integer value (for example a `LongTensor` if you're using PyTorch or a `np.int64` for Numpy users), and the fixed exponent. For example, we could set the precision to $10^{-6}$, and a number like $123.456$ would be encoded as $123456000 \\times 10^{-6}$.\n",
    "\n",
    "This makes addition very easy because you don't have any rescaling to compute: you just have to sum the integers values and keep the exponent unchanged. One limitation however of fixed precision is that the range of values you can store is much more limited, you can’t store numbers smaller than $10^{-6}$ in the example above. In addition, the smaller the precision (like if you reduce from 6 to 2), the bigger the rounding error of your encoding. In practice, as we are doing classic statistics and machine learning, such encoding is good enough to achieve accuracies close to floating point precision.\n",
    "\n",
    "There is one subtlety however, which has to do with multiplication. Let's consider for example the multiplication of $1.2$ and $2.0$ encoded with a decimal precision of 2, so $120 \\times 10^{-2}$ and $200 \\times 10^{-2}$. If we multiply the integer part, and keep one of the encodings, we end up with $24000 \\times 10^{-2}$ so $240$ instead of $2.4$. We can either increase the precision from 2 to 4, but in the fixed precision setting we really want the precision to remain constant, or we can truncate the integer part, by removing the 2 least significant digits which correspond to the current precision of 2: $(24000 // 10^2) \\times 10^{-2} = 240 \\times 10^{-2} = 2.4$.\n",
    "\n",
    "So far, we have been considering the decimal precision, i.e with base 10, but in practice it's more suitable to use the bit precision, i.e with base 2, because the size of the mantissa is expressed in number of bits. $1.5$ encoded in a bit precision of 3 would be $12 \\times 2^{-3}$. We will use both in the rest of the course.\n",
    "\n",
    "Ok this was a lot of theory, let's practice now!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing a fixed precision encoder and decoder\n",
    "\n",
    "We will now implement this fixed precision mechanism, to be able to better understand it. We will consider that the `base` and the `precision` are public parameters.\n",
    "\n",
    "Let's start by building the encoder and the decoder.\n",
    "\n",
    "Note:\n",
    "- You should round values to the nearest integer.\n",
    "- We used typing annotations, which can be useful hints in same cases 😉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we import the answer checker\n",
    "from quiz import test_encode, test_decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = 10\n",
    "precision = 3\n",
    "\n",
    "def encode(x: float, base: int, precision: int) -> int: \n",
    "    # complete the function to encode values in fixed precision\n",
    "    x = x * (base ** precision)\n",
    "    return round(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the following cell to check that your function behaves properly. It will run some tests and return an error if it encounters an unexpected result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;32mSuccess: \u001b[0mNicely done! 🙌\n"
     ]
    }
   ],
   "source": [
    "# run to check your function\n",
    "test_encode.check(encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each coding exercise, you will also have a hint, and the solution if you are blocked. Don't forget do use it if you're blocked!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the line below to see a hint\n",
    "# test_encode.hint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the line below to see the solution\n",
    "# test_encode.solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the decoder now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(x: float, base: int, precision: int) -> float:\n",
    "    # complete the function to decode fixed precision values\n",
    "    x = x / (base ** precision)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;32mSuccess: \u001b[0mWell done!\n"
     ]
    }
   ],
   "source": [
    "# run to check your function\n",
    "test_decode.check(decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the line below to see a hint\n",
    "# test_decode.hint\n",
    "# Uncomment the line below to see the solution\n",
    "# test_decode.solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's play a bit with our functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1875\n"
     ]
    }
   ],
   "source": [
    "base = 10\n",
    "precision = 3\n",
    "\n",
    "assert encode(1.2, base, precision) == 1200\n",
    "assert encode(1.0008, base, precision) == 1001 # Values with decimal after the 3rd are rounded\n",
    "\n",
    "assert decode(1200, base, precision) == 1.2\n",
    "assert decode(1001, base, precision) == 1.001 # Hence the decoding is only approximate here\n",
    "\n",
    "\n",
    "# Let's change the base\n",
    "base = 2\n",
    "precision = 5\n",
    "\n",
    "assert encode(1.2, base, precision) == 38\n",
    "\n",
    "print(decode(38, base, precision))\n",
    "# Note, you can observe the rounding error here, as it doesn't decode to 1.2 exactly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operating on fixed precision values\n",
    "\n",
    "We should now be well equipped to perform additions! Let's check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_fp, y_fp : 1229 1126\n",
      "z_fp : 2355\n",
      "computed sum: 2.2998046875 expected: 2.3\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "base = 2\n",
    "precision = 10\n",
    "\n",
    "x, y = 1.2, 1.1\n",
    "\n",
    "# _fp stands for \"fixed precision\"\n",
    "x_fp, y_fp = encode(x, base, precision), encode(y, base, precision)\n",
    "\n",
    "print(\"x_fp, y_fp :\", x_fp, y_fp)\n",
    "\n",
    "z_fp = x_fp + y_fp\n",
    "\n",
    "print(\"z_fp :\", z_fp)\n",
    "\n",
    "z = decode(z_fp, base, precision)\n",
    "\n",
    "diff = z - (x + y)\n",
    "assert np.abs(diff) <= base ** -precision # we check that the rounding error is \"small\"\n",
    "\n",
    "print('computed sum:', z, 'expected:', x + y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, to compute multiplication, we need to add the truncation mechanism. Let's implement it! \n",
    "\n",
    "Write the code for the `truncation` and the `mul` functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base = 10\n",
    "precision = 3\n",
    "\n",
    "def truncate(x: int, base: int, precision: int) -> int:\n",
    "    x = x // (base ** precision)\n",
    "    return x\n",
    "    \n",
    "def mul(x: int, y: int, base: int, precision: int) -> int:\n",
    "    z = x * y\n",
    "    z = truncate(z, base, precision)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;32mSuccess: \u001b[0mAll good!\n",
      "\u001b[1;32mSuccess: \u001b[0mNicely done!\n"
     ]
    }
   ],
   "source": [
    "# we import the answer checker\n",
    "from quiz import test_fp_truncate, test_fp_mul\n",
    "\n",
    "test_fp_truncate.check(truncate)\n",
    "\n",
    "test_fp_mul.check(mul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the line below to see a hint\n",
    "# test_fp_truncate.hint\n",
    "# Uncomment the line below to see the solution\n",
    "# test_fp_truncate.solution\n",
    "\n",
    "# Uncomment the line below to see a hint\n",
    "# test_fp_mul.hint\n",
    "# Uncomment the line below to see the solution\n",
    "# test_fp_mul.solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_fp, y_fp : 1200 2000\n",
      "z_fp : 2400\n"
     ]
    }
   ],
   "source": [
    "x_fp = encode(1.2, base, precision)\n",
    "y_fp = encode(2.0, base, precision)\n",
    "\n",
    "print(\"x_fp, y_fp :\", x_fp, y_fp)\n",
    "\n",
    "z_fp = mul(x_fp, y_fp, base, precision)\n",
    "\n",
    "print(\"z_fp :\", z_fp)\n",
    "z = decode(z_fp, base, precision)\n",
    "\n",
    "assert z == 2.4 # It's working just fine!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement matrix multiplication in fixed precision, you could follow exactly the same steps, you just have to replace `*` with `@`, the matrix multiplication operator.\n",
    "\n",
    "Excellent! At this point we are well equipped to operate on fixed precision numbers. Now, let's go a bit further and instead of considering fixed precision encoding of public numbers, let's consider fixed precision encoding of secret shared numbers, we're doing SMC after all!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application to secret sharing\n",
    "\n",
    "As we recall in SMC, shares are not float values but integers in a sufficiently big space, for example in $\\mathbb{Z}_{2^{n}}$, the space of the numbers encoded on $n$ bits, with typically $n=32$. We will apply the mechanisms we have just seen to secret shared numbers.\n",
    "\n",
    "In practice, we assume that a private value is first encoded to fixed precision before being secret shared, and we want to study how fixed precision impacts basic operations like:\n",
    "- Addition\n",
    "- Division by a public constant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For addition, the great news is that there is nothing to change! In the computation $x + y$, each party still sum his shares of $x$ and $y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For division by a public constant, which is a very common operation that you perform for example when you compute the mean $\\frac{1}{n} \\sum_{i=1}^n x_i$, things get a bit more complicated!\n",
    "\n",
    "Indeed, the most basic idea would be to ask each party to compute the division on its share, so that when the shares are summed up, the result will be the original result divided by the public constant. \n",
    "\n",
    "Let's use examples to see how this naive method behaves:\n",
    "\n",
    "##### A working public division\n",
    "\n",
    "We consider shares to be in $\\mathbb{Z}_{2^{4}}$ to simplify the computation. $\\mathbb{Z}_{2^{4}}$ represents all the integers in the range $[-8, 7 ]$. Indeed, $2^{4} = 16$ and we consider signed numbers, so instead of the range $[0, 15]$, we use $[-8, 7]$. We will get back to this convention a bit later.\n",
    "\n",
    "Let's consider $x = 4$, shared between Alice and Bob as such: $[x] = (x_{alice}, x_{bob}) = (-2, 6)$. If each party computes the division by 2 on its share, we obtain $(-1, 3)$ which reconstructs to $2$, and which is the correct result.\n",
    "\n",
    "But sometimes, we are not as lucky...\n",
    "\n",
    "##### A non-working public division\n",
    "\n",
    "Let's now consider $x = -4$, shared as such: $[x] = (x_{alice}, x_{bob}) = (6, 6)$. This sharing is correct since 6 + 6 = 12 which maps to 12 - 16 = -4 in $\\mathbb{Z}_{2^{4}}$. We say that there is a _wrap around_, as we exceeded the maximum value of our space, 7. Dividing the shares by 2 like before would lead to a sharing (3, 3), which reconstructs to $6 \\neq -4/2$. It's failing!!\n",
    "\n",
    "So what happened? Actually the shared result (3, 3) is still valid, but no longer in $\\mathbb{Z}_{2^{4}}$ but in the space of values divided by 2, namely $\\mathbb{Z}_{2^{3}}$. Indeed, $\\mathbb{Z}_{2^{3}}$ represents the range $[-4, 3]$, so 3 + 3 = 6 should map to 6 - 8 = -2 in $\\mathbb{Z}_{2^{3}}$. However, we want to keep the same space for all the shares that we are using, so we need to find a workaround.\n",
    "\n",
    "The reason why it failed is because of the _wrap around_, which happens when we sum the shares of $x$ but not when we sum the shares of $x / 2$. It is not possible for any of the parties holding a single share of $x$ to know if there is a wrap around $\\theta_x$, because it would reveal information about the other parties shares. However, they can privately compute the wrap around and obtain a secret shared $[\\theta_x]$. Computing such $[\\theta_x]$ is non-trivial, and we will leave as a black box the function that computes it.\n",
    "\n",
    "Having access to $[\\theta_x]$ helps to compute privately and correctly $x / k$ in $\\mathbb{Z}_{2^{n}}$ using the following formula:\n",
    "$$ [x / k] = [x] / k - [\\theta_x] \\cdot 2^{n} / k$$\n",
    "This means that each party divides naively its shares, and they jointly correct the result if there was a wrap around (i.e. if $\\theta_x \\neq 0$).\n",
    "\n",
    "You can check on the previous non-working example that this formula works. Indeed, we have $\\theta_x = 1$ and $2^{n} / k = 16 / 2 = 8$. If we assume $[\\theta_x]= (1, 0)$, then the shares of the result would not be $(3, 3)$ but $(-5, 3)$, which sums up to $-2$. Et voilà!\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra note: numerical errors in division\n",
    "\n",
    "You've been through the most intense part, and before we switch to multiplication and truncation, we just make a note on the numerical errors when using small fields. In the examples above, we have been playing in $\\mathbb{Z}_{2^{4}}$.\n",
    "\n",
    "If we consider $x = 4$ to be shared in $\\mathbb{Z}_{2^{4}}$ as such: $[x] = (1, 3)$, and that we apply division per 2, even with our method involving $\\theta_x$ that is 0 here, we will end up with shares (0, 1) (because 1 // 2 = 0 and 3 // 2 = 1), that sum up to $1 \\neq 4/2$.\n",
    "\n",
    "The rounding error here causes the result to be completely incorrect, but for bigger spaces like $\\mathbb{Z}_{2^{32}}$ that we usually consider, this error will be less important. Just remember that it is here, and that it can impact marginally your computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiplication with secret shared fixed precision numbers\n",
    "\n",
    "We have seen previously that multiplication with fixed precision values requires to use truncation. Since the parameters of the fixed precision (the base and the precision) are public, we can observe that truncation is just a public division, which we now have learned to do correctly!\n",
    "\n",
    "For example, for a base of 10 and a precision of 3, truncation is just the division by 1000. For base 2 and precision 2, it is the division by 4. Easy, isn't it?\n",
    "\n",
    "Let's write the code to do this private multiplication using truncation. We will assume that we can use the following functions:\n",
    "- `encode(x: float) -> int`, that encode real numbers to fixed precision\n",
    "- `decode(x: int) -> float`, that convert fixed precision numbers back to floats.\n",
    "- `secret_share(x: int) -> List[int]`, that builds shares of a fixed precision number\n",
    "- `decrypt(shares: List[int]) -> int`, that reconstructs a fixed precision number from its shares\n",
    "- `spdz_mul(x_shares: List[int], y_shares: List[int]) -> List[int]`, that given $x$ and $y$ shared integers, returns the shares of $x * y$  \n",
    "- `wrap_around(shares: List[int]) -> List[int]`, that given some shares return the number of wrap arounds in a secret shared fashion\n",
    "\n",
    "We have removed the `base`, `precision` and `bits` arguments in the functions, we will assume that they are globally set and equal to `10`, `2` and `32` respectively for the checks.\n",
    "\n",
    "You should follow the implementation of the previous section, by defining a `mul` function that will call a `truncate` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quiz import encode, decode, secret_share, decrypt, spdz_mul, wrap_around\n",
    "from typing import List\n",
    "\n",
    "base = 10\n",
    "precision = 3\n",
    "bits = 32 # on how many bits we encode our fixed precision values and shares\n",
    "n = 2 ** bits\n",
    "k = base ** precision\n",
    "\n",
    "def truncate(x_shares: List[int]) -> List[int]:\n",
    "    # Write your code here\n",
    "    x_shares1 = []\n",
    "    theta_shares = wrap_around(x_shares)\n",
    "    for x, theta in zip(x_shares, theta_shares):\n",
    "        x_shares1.append(int(x/k)-int(theta*n/k))\n",
    "    return x_shares1\n",
    "\n",
    "def mul(x_shares: List[int], y_shares: List[int]) -> List[int]:\n",
    "    # Write your code here\n",
    "    z_shares = spdz_mul(x_shares, y_shares)\n",
    "    z_shares = truncate(z_shares)\n",
    "    return z_shares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;32mSuccess: \u001b[0mExcellent! This was not an easy one 🙌\n"
     ]
    }
   ],
   "source": [
    "# we import the answer checker\n",
    "from quiz import test_truncate, test_mul\n",
    "\n",
    "test_truncate.check(truncate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33mHint: \u001b[0m\n",
      "Try to analyze the formula and the explanation provided for the exact truncation.\n",
      "You will need to call wrap_around().\n",
      "\n",
      "\u001b[1;34mSolution: \u001b[0m\n",
      "def truncate(x_shares: List[int]) -> List[int]:\n",
      "    theta_shares = wrap_around(x_shares)\n",
      "    \n",
      "    truncated_shares = []\n",
      "    for x_share, theta_share in zip(x_shares, theta_shares):\n",
      "        truncated_shares.append(\n",
      "            int(x_share / base ** precision) - theta_share * int(2 ** bits / base ** precision)\n",
      "        )\n",
      "        \n",
      "    return truncated_shares\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Uncomment the line below to see a hint\n",
    "test_truncate.hint\n",
    "# Uncomment the line below to see the solution\n",
    "test_truncate.solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;32mSuccess: \u001b[0mWell done! 🙌\n"
     ]
    }
   ],
   "source": [
    "test_mul.check(mul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the line below to see a hint\n",
    "# test_mul.hint\n",
    "# Uncomment the line below to see the solution\n",
    "# test_mul.solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you are! We have now explored most of the subtleties of combining fixed precision with secret sharing. All of this complexity is completely hidden when you are using PySyft, as it takes care of this for you.\n",
    "\n",
    "Here is the equivalent code you would write with PySyft:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2022-01-18T17:06:22.770275+0800][CRITICAL][logger]][30960] <class 'syft.core.store.store_memory.MemoryStore'> __delitem__ error <UID: 5c807980a0f5491ea5d5f5cc7a799ddb>.\n",
      "[2022-01-18T17:06:22.772277+0800][CRITICAL][logger]][30960] <class 'syft.core.store.store_memory.MemoryStore'> __delitem__ error <UID: 1d6265a0ce8f4126af1772fab417af08>.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.5200])\n"
     ]
    }
   ],
   "source": [
    "import syft as sy\n",
    "import torch\n",
    "from sympc.session import Session,SessionManager\n",
    "from sympc.tensor import MPCTensor\n",
    "\n",
    "alice = sy.VirtualMachine(name=\"Alice\").get_client()\n",
    "bob = sy.VirtualMachine(name=\"Bob\").get_client()\n",
    "\n",
    "session = Session(parties=(alice, bob))\n",
    "SessionManager.setup_mpc(session) # change Session into SessionManager\n",
    "\n",
    "x_secret = torch.Tensor([1.2])\n",
    "y_secret = torch.Tensor([2.1])\n",
    "\n",
    "x = MPCTensor(secret=x_secret, session=session)\n",
    "y = MPCTensor(secret=y_secret, session=session)\n",
    "\n",
    "result = (x * y).reconstruct()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------\n",
    "需要注意：\n",
    "```\n",
    "pip install torchcsprng==0.2.1+cpu -f https://download.pytorch.org/whl/torch_stable.html\n",
    "pip install sycret\n",
    "```\n",
    "-----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now take a little tour in theory! In the next part, you will be discovering more about the security guarantees that you can have as a user of secure multi-party computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
