{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft as sy\n",
    "duet = sy.duet(loopback=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duet.requests.add_handler(action=\"accept\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duet.store.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5000, 784])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "from six.moves import urllib\n",
    "opener = urllib.request.build_opener()\n",
    "opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "urllib.request.install_opener(opener)\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "trainset = datasets.MNIST('mnist', download=True, train=True, transform=transform)\n",
    "# valset = datasets.MNIST('mnist', download=True, train=False, transform=transform)\n",
    "\n",
    "\n",
    "data = trainset.data.view(trainset.data.shape[0], -1).float()\n",
    "data = data[:5000]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.send(duet, searchable=True, tags=[\"train_mnist\"], description=\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5000, 784])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "dataloader = torch.utils.data.DataLoader(data, batch_size=128)\n",
    "\n",
    "labels = trainset.targets[:5000]\n",
    "targetloader = torch.utils.data.DataLoader(labels, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import syft as sy\n",
    "\n",
    "input_size = 784\n",
    "hidden_sizes = [256, 500]\n",
    "output_size = 10\n",
    "\n",
    "class SyNet_client(sy.Module):\n",
    "    def __init__(self, torch_ref):\n",
    "        super(SyNet_client, self).__init__(torch_ref=torch_ref)\n",
    "        self.lin = nn.Linear(input_size, hidden_sizes[0])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.lin(x)\n",
    "        x = self.torch_ref.nn.functional.relu(x)\n",
    "        return x\n",
    "    \n",
    "class SyNet_server(sy.Module):\n",
    "    def __init__(self, torch_ref):\n",
    "        super(SyNet_server, self).__init__(torch_ref=torch_ref)\n",
    "        self.lin2 = nn.Linear(hidden_sizes[0], hidden_sizes[1])\n",
    "        self.lin3 = nn.Linear(hidden_sizes[1], output_size)\n",
    "        self.sft = nn.LogSoftmax(dim=1) \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.lin2(x)\n",
    "        x = self.torch_ref.nn.functional.relu(x)\n",
    "        x = self.lin3(x)\n",
    "        x = self.torch_ref.nn.functional.relu(x)\n",
    "        x = self.sft(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 1\n",
    "model1 = SyNet_client(torch)\n",
    "# model1_ptr = model1.send(duet)\n",
    "opt1 = torch.optim.SGD(params=model1.parameters(),lr=0.03)\n",
    "\n",
    "#Model 2\n",
    "model2 = SyNet_server(torch)\n",
    "opt2 = torch.optim.SGD(params=model2.parameters(),lr=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.6705, grad_fn=<NllLossBackward>)\n",
      "tensor(941.7748, grad_fn=<NllLossBackward>)\n",
      "tensor(19460.0645, grad_fn=<NllLossBackward>)\n",
      "tensor(28833.9766, grad_fn=<NllLossBackward>)\n",
      "tensor(120202.1016, grad_fn=<NllLossBackward>)\n",
      "tensor(313913.8438, grad_fn=<NllLossBackward>)\n",
      "tensor(2119398.7500, grad_fn=<NllLossBackward>)\n",
      "tensor(1066598.1250, grad_fn=<NllLossBackward>)\n",
      "tensor(139424.5156, grad_fn=<NllLossBackward>)\n",
      "tensor(13.6937, grad_fn=<NllLossBackward>)\n",
      "tensor(3.7452, grad_fn=<NllLossBackward>)\n",
      "tensor(3.8513, grad_fn=<NllLossBackward>)\n",
      "tensor(30.8226, grad_fn=<NllLossBackward>)\n",
      "tensor(154623.7500, grad_fn=<NllLossBackward>)\n",
      "tensor(2.5973e+09, grad_fn=<NllLossBackward>)\n",
      "tensor(373656.7188, grad_fn=<NllLossBackward>)\n",
      "tensor(688.9954, grad_fn=<NllLossBackward>)\n",
      "tensor(281.7310, grad_fn=<NllLossBackward>)\n",
      "tensor(72313.5156, grad_fn=<NllLossBackward>)\n",
      "tensor(149.3159, grad_fn=<NllLossBackward>)\n",
      "tensor(31.1291, grad_fn=<NllLossBackward>)\n",
      "tensor(15.2911, grad_fn=<NllLossBackward>)\n",
      "tensor(5747.3931, grad_fn=<NllLossBackward>)\n",
      "tensor(2.8914, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3819, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3418, grad_fn=<NllLossBackward>)\n",
      "tensor(2.4071, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3114, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3140, grad_fn=<NllLossBackward>)\n",
      "tensor(46.2574, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3207, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3305, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3086, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3430, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2991, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3118, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3604, grad_fn=<NllLossBackward>)\n",
      "tensor(2.8240, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2666, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3750, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3432, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3270, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3650, grad_fn=<NllLossBackward>)\n",
      "tensor(118.2001, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3389, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3570, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3090, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3153, grad_fn=<NllLossBackward>)\n",
      "tensor(2351.4724, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3144, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2965, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3315, grad_fn=<NllLossBackward>)\n",
      "tensor(2.4680, grad_fn=<NllLossBackward>)\n",
      "tensor(2.4148, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2745, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3651, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3221, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3379, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3152, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3374, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3114, grad_fn=<NllLossBackward>)\n",
      "tensor(2.5769, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3504, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3218, grad_fn=<NllLossBackward>)\n",
      "tensor(3.8518, grad_fn=<NllLossBackward>)\n",
      "tensor(98.3773, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2994, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3256, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2844, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2895, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3345, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3276, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3201, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3334, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2843, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2945, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3279, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3439, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3522, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "for images, target in zip(dataloader, targetloader):    \n",
    "    opt1.zero_grad()\n",
    "    opt2.zero_grad()\n",
    "    \n",
    "    pred = model2(model1(images))\n",
    "    criterion = nn.NLLLoss()\n",
    "    loss = criterion(pred, target)\n",
    "    loss.backward()\n",
    "        \n",
    "    opt1.step()\n",
    "    opt2.step()\n",
    "    print(loss)\n",
    "    \n",
    "#     print(activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
