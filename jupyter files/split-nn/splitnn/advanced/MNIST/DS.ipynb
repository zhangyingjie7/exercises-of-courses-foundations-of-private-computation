{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 - Pull in dependencies and initiate Duet session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¤  ðŸŽ¸  â™ªâ™ªâ™ª Joining Duet â™«â™«â™«  ðŸŽ»  ðŸŽ¹\n",
      "\n",
      "â™«â™«â™« >\u001b[93m DISCLAIMER\u001b[0m: \u001b[1mDuet is an experimental feature currently in beta.\n",
      "â™«â™«â™« > Use at your own risk.\n",
      "\u001b[0m\n",
      "\u001b[1m\n",
      "    > â¤ï¸ \u001b[91mLove\u001b[0m \u001b[92mDuet\u001b[0m? \u001b[93mPlease\u001b[0m \u001b[94mconsider\u001b[0m \u001b[95msupporting\u001b[0m \u001b[91mour\u001b[0m \u001b[93mcommunity!\u001b[0m\n",
      "    > https://github.com/sponsors/OpenMined\u001b[1m\n",
      "\n",
      "â™«â™«â™« > Punching through firewall to OpenGrid Network Node at:\n",
      "â™«â™«â™« > http://ec2-18-218-7-180.us-east-2.compute.amazonaws.com:5000\n",
      "â™«â™«â™« >\n",
      "â™«â™«â™« > ...waiting for response from OpenGrid Network... \n",
      "â™«â™«â™« > \u001b[92mDONE!\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\program files\\python\\python37\\tutorial-env\\lib\\site-packages\\aiortc\\rtcdtlstransport.py:211: CryptographyDeprecationWarning: This version of cryptography contains a temporary pyOpenSSL fallback path. Upgrade pyOpenSSL now.\n",
      "  _openssl_assert(lib.SSL_CTX_use_certificate(ctx, self._cert._x509) == 1)  # type: ignore\n",
      "d:\\program files\\python\\python37\\tutorial-env\\lib\\site-packages\\aiortc\\rtcdtlstransport.py:186: CryptographyDeprecationWarning: This version of cryptography contains a temporary pyOpenSSL fallback path. Upgrade pyOpenSSL now.\n",
      "  value=certificate_digest(self._cert._x509),  # type: ignore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â™«â™«â™« > \u001b[92mCONNECTED!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# First lets pull in our dependencies and initiate our duet session\n",
    "import torch\n",
    "import random\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import syft as sy\n",
    "\n",
    "duet = sy.join_duet(loopback=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Define and send our remote assets\n",
    "\n",
    "Here we'll define the remote model which will have the remote input data fed into it. This includes;\n",
    "\n",
    "- Our first model segment\n",
    "- Our dummy input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5000])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "from six.moves import urllib\n",
    "opener = urllib.request.build_opener()\n",
    "opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "urllib.request.install_opener(opener)\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "trainset = datasets.MNIST('mnist', download=True, train=True, transform=transform)\n",
    "# valset = datasets.MNIST('mnist', download=True, train=False, transform=transform)\n",
    "\n",
    "labels = trainset.targets[:5000]\n",
    "data = duet.store[0]\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = duet.torch.utils.data.DataLoader(data, batch_size=128)\n",
    "targetloader = torch.utils.data.DataLoader(labels, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "hidden_sizes = [128, 500]\n",
    "output_size = 10\n",
    "\n",
    "class SyNet_client(sy.Module):\n",
    "    def __init__(self, torch_ref):\n",
    "        super(SyNet_client, self).__init__(torch_ref=torch_ref)\n",
    "        self.lin = nn.Linear(input_size, hidden_sizes[0])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.lin(x)\n",
    "        x = self.torch_ref.nn.functional.relu(x)\n",
    "        return x\n",
    "    \n",
    "class SyNet_server(sy.Module):\n",
    "    def __init__(self, torch_ref):\n",
    "        super(SyNet_server, self).__init__(torch_ref=torch_ref)\n",
    "        self.lin2 = nn.Linear(hidden_sizes[0], hidden_sizes[1])\n",
    "        self.lin3 = nn.Linear(hidden_sizes[1], output_size)\n",
    "        self.sft = nn.LogSoftmax(dim=1) \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.lin2(x)\n",
    "        x = nn.ReLU()(x)\n",
    "        x = self.lin3(x)\n",
    "        x = self.sft(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 1\n",
    "model1 = SyNet_client(torch)\n",
    "model1_ptr = model1.send(duet)\n",
    "opt1 = duet.torch.optim.SGD(params=model1_ptr.parameters(),lr=0.01)\n",
    "\n",
    "#Model 2\n",
    "model2 = SyNet_server(torch)\n",
    "opt2 = torch.optim.SGD(params=model2.parameters(),lr=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Define our training logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'retain_grad'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-6368188cd0c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mactivation_ptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel1_ptr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_pointer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivation_ptr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_block\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mactivation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretain_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#         print(activation[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'retain_grad'"
     ]
    }
   ],
   "source": [
    "for images, target in zip(dataloader, targetloader):\n",
    "    opt1.zero_grad()\n",
    "    opt2.zero_grad()\n",
    "    \n",
    "    print(target.type)\n",
    "    \n",
    "    activation_ptr = model1_ptr(images)\n",
    "    activation = activation_ptr.clone().get(request_block=True)\n",
    "    \n",
    "    pred = model2(activation)\n",
    "    \n",
    "    criterion = nn.NLLLoss()\n",
    "#     print(pred)\n",
    "    loss = criterion(pred, target.long())\n",
    "    \n",
    "#     train_correct += pred.max(1)[1].eq(target).sum().item()\n",
    "#     train_total += pred.shape[0]\n",
    "#     print(loss)\n",
    "    \n",
    "    loss.backward()\n",
    "    grad_ptr = activation.grad.clone().send(duet)\n",
    "    activation_ptr.backward(grad_ptr)\n",
    "    \n",
    "    opt1.step()\n",
    "    opt2.step()\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Pull in our Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_kwargs = {\n",
    "    \"batch_size\": args[\"test_batch_size\"],\n",
    "}\n",
    "\n",
    "test_data = torchvision.datasets.MNIST('../data', train=False, download=True, transform=local_transforms)\n",
    "test_loader = torch.utils.data.DataLoader(test_data,**train_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model1 = model1_ptr.get(request_block=True, reason=\"run testing ont the model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Test our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test_data_length = len(test_loader.dataset)\n",
    "# test_batches = round((test_data_length / args[\"test_batch_size\"]) + 0.5)\n",
    "# test_loss = 0.0\n",
    "# correct = 0.0\n",
    "    \n",
    "# for batch_idx, (data, target) in enumerate(test_loader):\n",
    "#     output = model2(model1(data))\n",
    "#     iter_loss = torch.nn.functional.nll_loss(output, target, reduction=\"sum\").item()\n",
    "#     test_loss = test_loss + iter_loss\n",
    "#     pred = output.argmax(dim=1)\n",
    "#     total = pred.eq(target).sum().item()\n",
    "#     correct += total\n",
    "            \n",
    "#     if batch_idx >= test_batches - 1:\n",
    "#                 print(\"batch_idx >= test_batches, breaking\")\n",
    "#                 break\n",
    "#     accuracy = correct / test_data_length\n",
    "#     print(f\"Test Set Accuracy: {test_loss}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
