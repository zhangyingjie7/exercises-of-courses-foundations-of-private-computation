{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¤  ðŸŽ¸  â™ªâ™ªâ™ª Starting Duet â™«â™«â™«  ðŸŽ»  ðŸŽ¹\n",
      "\n",
      "â™«â™«â™« >\u001b[93m DISCLAIMER\u001b[0m: \u001b[1mDuet is an experimental feature currently in beta.\n",
      "â™«â™«â™« > Use at your own risk.\n",
      "\u001b[0m\n",
      "\u001b[1m\n",
      "    > â¤ï¸ \u001b[91mLove\u001b[0m \u001b[92mDuet\u001b[0m? \u001b[93mPlease\u001b[0m \u001b[94mconsider\u001b[0m \u001b[95msupporting\u001b[0m \u001b[91mour\u001b[0m \u001b[93mcommunity!\u001b[0m\n",
      "    > https://github.com/sponsors/OpenMined\u001b[1m\n",
      "\n",
      "â™«â™«â™« > Punching through firewall to OpenGrid Network Node at:\n",
      "â™«â™«â™« > http://ec2-18-218-7-180.us-east-2.compute.amazonaws.com:5000\n",
      "â™«â™«â™« >\n",
      "â™«â™«â™« > ...waiting for response from OpenGrid Network... \n",
      "â™«â™«â™« > \u001b[92mDONE!\u001b[0m\n",
      "\n",
      "â™«â™«â™« > \u001b[95mSTEP 1:\u001b[0m Send the following code to your Duet Partner!\n",
      "\n",
      "import syft as sy\n",
      "duet = sy.join_duet(loopback=True)\n",
      "\n",
      "â™«â™«â™« > Connecting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\program files\\python\\python37\\tutorial-env\\lib\\site-packages\\aiortc\\rtcdtlstransport.py:211: CryptographyDeprecationWarning: This version of cryptography contains a temporary pyOpenSSL fallback path. Upgrade pyOpenSSL now.\n",
      "  _openssl_assert(lib.SSL_CTX_use_certificate(ctx, self._cert._x509) == 1)  # type: ignore\n",
      "d:\\program files\\python\\python37\\tutorial-env\\lib\\site-packages\\aiortc\\rtcdtlstransport.py:186: CryptographyDeprecationWarning: This version of cryptography contains a temporary pyOpenSSL fallback path. Upgrade pyOpenSSL now.\n",
      "  value=certificate_digest(self._cert._x509),  # type: ignore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â™«â™«â™« > \u001b[92mCONNECTED!\u001b[0m\n",
      "\n",
      "`searchable` is deprecated please use `pointable` in futurees: 4  Request Handlers: 1                                \n",
      "â™«â™«â™« > DUET LIVE STATUS  -  Objects: 1  Requests: 0   Messages: 5  Request Handlers: 1                                \r"
     ]
    }
   ],
   "source": [
    "import syft as sy\n",
    "duet = sy.duet(loopback=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "duet.requests.add_handler(action=\"accept\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duet.store.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5000, 784])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "from six.moves import urllib\n",
    "opener = urllib.request.build_opener()\n",
    "opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "urllib.request.install_opener(opener)\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "trainset = datasets.MNIST('mnist', download=True, train=True, transform=transform)\n",
    "# valset = datasets.MNIST('mnist', download=True, train=False, transform=transform)\n",
    "\n",
    "\n",
    "data = trainset.data.view(trainset.data.shape[0], -1).float()\n",
    "data = data[:5000]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<syft.proxy.torch.TensorPointer at 0x2465ce2b438>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.send(duet, searchable=True, tags=[\"train_mnist\"], description=\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5000, 784])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "dataloader = torch.utils.data.DataLoader(data, batch_size=128)\n",
    "\n",
    "labels = trainset.targets[:5000]\n",
    "targetloader = torch.utils.data.DataLoader(labels, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import syft as sy\n",
    "\n",
    "input_size = 784\n",
    "hidden_sizes = [256, 500]\n",
    "output_size = 10\n",
    "\n",
    "class SyNet_client(sy.Module):\n",
    "    def __init__(self, torch_ref):\n",
    "        super(SyNet_client, self).__init__(torch_ref=torch_ref)\n",
    "        self.lin = nn.Linear(input_size, hidden_sizes[0])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.lin(x)\n",
    "        x = self.torch_ref.nn.functional.relu(x)\n",
    "        return x\n",
    "    \n",
    "class SyNet_server(sy.Module):\n",
    "    def __init__(self, torch_ref):\n",
    "        super(SyNet_server, self).__init__(torch_ref=torch_ref)\n",
    "        self.lin2 = nn.Linear(hidden_sizes[0], hidden_sizes[1])\n",
    "        self.lin3 = nn.Linear(hidden_sizes[1], output_size)\n",
    "        self.sft = nn.LogSoftmax(dim=1) \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.lin2(x)\n",
    "        x = self.torch_ref.nn.functional.relu(x)\n",
    "        x = self.lin3(x)\n",
    "        x = self.torch_ref.nn.functional.relu(x)\n",
    "        x = self.sft(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 1\n",
    "model1 = SyNet_client(torch)\n",
    "# model1_ptr = model1.send(duet)\n",
    "opt1 = torch.optim.SGD(params=model1.parameters(),lr=0.03)\n",
    "\n",
    "#Model 2\n",
    "model2 = SyNet_server(torch)\n",
    "opt2 = torch.optim.SGD(params=model2.parameters(),lr=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.6705, grad_fn=<NllLossBackward>)\n",
      "tensor(941.7748, grad_fn=<NllLossBackward>)\n",
      "tensor(19460.0645, grad_fn=<NllLossBackward>)\n",
      "tensor(28833.9766, grad_fn=<NllLossBackward>)\n",
      "tensor(120202.1016, grad_fn=<NllLossBackward>)\n",
      "tensor(313913.8438, grad_fn=<NllLossBackward>)\n",
      "tensor(2119398.7500, grad_fn=<NllLossBackward>)\n",
      "tensor(1066598.1250, grad_fn=<NllLossBackward>)\n",
      "tensor(139424.5156, grad_fn=<NllLossBackward>)\n",
      "tensor(13.6937, grad_fn=<NllLossBackward>)\n",
      "tensor(3.7452, grad_fn=<NllLossBackward>)\n",
      "tensor(3.8513, grad_fn=<NllLossBackward>)\n",
      "tensor(30.8226, grad_fn=<NllLossBackward>)\n",
      "tensor(154623.7500, grad_fn=<NllLossBackward>)\n",
      "tensor(2.5973e+09, grad_fn=<NllLossBackward>)\n",
      "tensor(373656.7188, grad_fn=<NllLossBackward>)\n",
      "tensor(688.9954, grad_fn=<NllLossBackward>)\n",
      "tensor(281.7310, grad_fn=<NllLossBackward>)\n",
      "tensor(72313.5156, grad_fn=<NllLossBackward>)\n",
      "tensor(149.3159, grad_fn=<NllLossBackward>)\n",
      "tensor(31.1291, grad_fn=<NllLossBackward>)\n",
      "tensor(15.2911, grad_fn=<NllLossBackward>)\n",
      "tensor(5747.3931, grad_fn=<NllLossBackward>)\n",
      "tensor(2.8914, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3819, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3418, grad_fn=<NllLossBackward>)\n",
      "tensor(2.4071, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3114, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3140, grad_fn=<NllLossBackward>)\n",
      "tensor(46.2574, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3207, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3305, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3086, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3430, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2991, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3118, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3604, grad_fn=<NllLossBackward>)\n",
      "tensor(2.8240, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2666, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3750, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3432, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3270, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3650, grad_fn=<NllLossBackward>)\n",
      "tensor(118.2001, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3389, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3570, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3090, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3153, grad_fn=<NllLossBackward>)\n",
      "tensor(2351.4724, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3144, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2965, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3315, grad_fn=<NllLossBackward>)\n",
      "tensor(2.4680, grad_fn=<NllLossBackward>)\n",
      "tensor(2.4148, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2745, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3651, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3221, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3379, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3152, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3374, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3114, grad_fn=<NllLossBackward>)\n",
      "tensor(2.5769, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3504, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3218, grad_fn=<NllLossBackward>)\n",
      "tensor(3.8518, grad_fn=<NllLossBackward>)\n",
      "tensor(98.3773, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2994, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3256, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2844, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2895, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3345, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3276, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3201, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3334, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2843, grad_fn=<NllLossBackward>)\n",
      "tensor(2.2945, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3279, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3439, grad_fn=<NllLossBackward>)\n",
      "tensor(2.3522, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "for images, target in zip(dataloader, targetloader):    \n",
    "    opt1.zero_grad()\n",
    "    opt2.zero_grad()\n",
    "    \n",
    "    pred = model2(model1(images))\n",
    "    criterion = nn.NLLLoss()\n",
    "    loss = criterion(pred, target)\n",
    "    loss.backward()\n",
    "        \n",
    "    opt1.step()\n",
    "    opt2.step()\n",
    "    print(loss)\n",
    "    \n",
    "#     print(activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
