{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "upset-tuning",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import syft as sy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adolescent-reset",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¤  ðŸŽ¸  â™ªâ™ªâ™ª Starting Duet â™«â™«â™«  ðŸŽ»  ðŸŽ¹\n",
      "\n",
      "â™«â™«â™« >\u001b[93m DISCLAIMER\u001b[0m: \u001b[1mDuet is an experimental feature currently in beta.\n",
      "â™«â™«â™« > Use at your own risk.\n",
      "\u001b[0m\n",
      "\u001b[1m\n",
      "    > â¤ï¸ \u001b[91mLove\u001b[0m \u001b[92mDuet\u001b[0m? \u001b[93mPlease\u001b[0m \u001b[94mconsider\u001b[0m \u001b[95msupporting\u001b[0m \u001b[91mour\u001b[0m \u001b[93mcommunity!\u001b[0m\n",
      "    > https://github.com/sponsors/OpenMined\u001b[1m\n",
      "\n",
      "â™«â™«â™« > Punching through firewall to OpenGrid Network Node at:\n",
      "â™«â™«â™« > http://ec2-18-218-7-180.us-east-2.compute.amazonaws.com:5000\n",
      "â™«â™«â™« >\n",
      "â™«â™«â™« > ...waiting for response from OpenGrid Network... \n",
      "â™«â™«â™« > \u001b[92mDONE!\u001b[0m\n",
      "\n",
      "â™«â™«â™« > \u001b[95mSTEP 1:\u001b[0m Send the following code to your Duet Partner!\n",
      "\n",
      "import syft as sy\n",
      "duet = sy.join_duet(loopback=True)\n",
      "\n",
      "â™«â™«â™« > Connecting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\program files\\python\\python37\\tutorial-env\\lib\\site-packages\\aiortc\\rtcdtlstransport.py:211: CryptographyDeprecationWarning: This version of cryptography contains a temporary pyOpenSSL fallback path. Upgrade pyOpenSSL now.\n",
      "  _openssl_assert(lib.SSL_CTX_use_certificate(ctx, self._cert._x509) == 1)  # type: ignore\n",
      "d:\\program files\\python\\python37\\tutorial-env\\lib\\site-packages\\aiortc\\rtcdtlstransport.py:186: CryptographyDeprecationWarning: This version of cryptography contains a temporary pyOpenSSL fallback path. Upgrade pyOpenSSL now.\n",
      "  value=certificate_digest(self._cert._x509),  # type: ignore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â™«â™«â™« > \u001b[92mCONNECTED!\u001b[0m\n",
      "\n",
      "â™«â™«â™« > DUET LIVE STATUS  *  Objects: 7  Requests: 0   Messages: 116  Request Handlers: 1                                \r"
     ]
    }
   ],
   "source": [
    "duet = sy.duet(loopback=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "defined-sharp",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(dataset, worker_list=None, n_workers=2):\n",
    "\n",
    "    if worker_list is None:\n",
    "        worker_list = list(range(0, n_workers))\n",
    "            \n",
    "    #counter to create the index of different data samples\n",
    "    idx = 0 \n",
    "    \n",
    "    #dictionary to accomodate the split data\n",
    "    dic_single_datasets = {}\n",
    "    for worker in worker_list: \n",
    "        \"\"\"\n",
    "        Each value is a list of three elements, to accomodate, in order: \n",
    "        - data examples (as tensors)\n",
    "        - label\n",
    "        - index \n",
    "        \"\"\"\n",
    "        dic_single_datasets[worker] = [] \n",
    "\n",
    "    \"\"\"\n",
    "    Loop through the dataset to split the data and labels vertically across workers. \n",
    "    Splitting method from @abbas5253: https://github.com/abbas5253/SplitNN-for-Vertically-Partitioned-Data/blob/master/distribute_data.py\n",
    "    \"\"\"\n",
    "    label_list = []\n",
    "    index_list = []\n",
    "    for tensor, label in dataset:\n",
    "        height = tensor.shape[-1]//len(worker_list)\n",
    "        i = 0\n",
    "        for worker in worker_list[:-1]: \n",
    "            dic_single_datasets[worker].append(tensor[:, :, height * i : height * (i + 1)])\n",
    "            i += 1\n",
    "            \n",
    "        #add the value of the last worker / split\n",
    "        dic_single_datasets[worker_list[-1]].append(tensor[:, :, height * (i) : ])\n",
    "        label_list.append(torch.Tensor([label]))\n",
    "        index_list.append(torch.Tensor([idx]))\n",
    "        \n",
    "        idx += 1\n",
    "        \n",
    "    return dic_single_datasets, label_list, index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "civic-superintendent",
   "metadata": {},
   "outputs": [],
   "source": [
    "from six.moves import urllib\n",
    "opener = urllib.request.build_opener()\n",
    "opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "urllib.request.install_opener(opener)\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "trainset = datasets.MNIST('mnist', download=True, train=True, transform=transform)\n",
    "valset = datasets.MNIST('mnist', download=True, train=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "static-jonathan",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, _, _ = split_data(trainset)\n",
    "img = torch.cat(img[1][:10_000])\n",
    "img_rshp = img.view(img.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "amino-secret",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 392])\n"
     ]
    }
   ],
   "source": [
    "print(img_rshp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "hungry-modification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5000, 392])\n"
     ]
    }
   ],
   "source": [
    "val_img, _, _ = split_data(valset)\n",
    "val_img = torch.cat(val_img[1][:5_000])\n",
    "val_img_rshp = val_img.view(val_img.shape[0], -1)\n",
    "print(val_img_rshp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ranking-ceramic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`searchable` is deprecated please use `pointable` in future\n",
      "`searchable` is deprecated please use `pointable` in future\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<syft.proxy.torch.TensorPointer at 0x25a3bcb7e80>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_rshp.send(duet, searchable=True, tags=[\"flatten\"], description=\"flattened\")\n",
    "val_img_rshp.send(duet, searchable=True, tags=[\"flatten_val\"], description=\"flattened validation data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "prime-search",
   "metadata": {},
   "outputs": [],
   "source": [
    "duet.requests.add_handler(action=\"accept\", tags=[\"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-natural",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
